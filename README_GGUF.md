# ðŸš€ Fine-tuning Qwen3-VL-8B-Instruct GGUF per LMStudio

## ðŸ“‹ Panoramica

Questo script Ã¨ **specificamente progettato** per fine-tunare il tuo modello **Qwen3-VL-8B-Instruct-Q4_K_M.gguf** da LMStudio su **AMD RX 6650 XT (8GB)**.

## ðŸŽ¯ Vantaggi di questa versione GGUF

âœ… **Parti da modello giÃ  ottimizzato** (Q4_K_M - 4-bit quantization)  
âœ… **Output compatibile con LMStudio** (formato GGUF)  
âœ… **Training piÃ¹ veloce** (nessun download da Hugging Face)  
âœ… **Memoria ottimizzata** per 8GB VRAM  
âœ… **Mantiene qualitÃ  originale** del modello  

## ðŸ› ï¸ Requisiti Specifici

- **GPU**: AMD Radeon RX 6650 XT (8GB GDDR6)
- **Modello**: Qwen3-VL-8B-Instruct-Q4_K_M.gguf (giÃ  in tuo possesso)
- **Sistema**: Windows 10/11 con ROCm support
- **Spazio**: 30GB liberi per training temporaneo

## ðŸš€ Comando Unico

```bash
python setup_and_train_gguf.py
```

**Tutto Ã¨ automatizzato!** Lo script eseguirÃ :

## ðŸ“Š Processo Dettagliato

### 1ï¸âƒ£ **Setup Ambiente** (5-10 min)
- Crea ambiente virtuale isolato `.venv_gguf/`
- Configura AMD ROCm: `HSA_OVERRIDE_GFX_VERSION=10.3.0`
- Installa dipendenze specifiche per GGUF

### 2ï¸âƒ£ **Verifica Modello** (1 min)
- Controlla il tuo file: `Qwen3-VL-8B-Instruct-Q4_K_M.gguf`
- Verifica dimensioni e integritÃ 
- Mostra info: ~4-6GB (4-bit quantization)

### 3ï¸âƒ£ **Preparazione Dataset** (2-3 min)
- **Converte** il tuo `technical_architecture_qwen3_amd.md`
- **Crea formato** domanda-risposta per training
- **Ottimizza** per contesto medico

### 4ï¸âƒ£ **Training GGUF** (4-8 ore)
- **Carica modello Q4_K_M** in memoria GPU
- **Applica LoRA fine-tuning** (rank=4, alpha=8)
- **Training medico** con 2 epochs
- **Monitoraggio memoria** in tempo reale
- **Salva checkpoints** ogni 100 steps

### 5ï¸âƒ£ **Conversione GGUF** (5-10 min)
- **Converte risultati** in formato GGUF
- **Mantiene quantizzazione** Q4_K_M
- **Crea file info** per LMStudio

### 6ï¸âƒ£ **Testing Finale** (2-3 min)
- **5 domande mediche** test (ITA/ENG)
- **Verifica qualitÃ ** risposte
- **Report performance**

## ðŸ“ Output Generato

```
./
â”œâ”€â”€ .venv_gguf/                    # Ambiente virtuale
â”œâ”€â”€ training_data_gguf/
â”‚   â””â”€â”€ medical_dataset_gguf.json  # Dataset convertito
â”œâ”€â”€ gguf_training_output/           # Risultati training
â”‚   â”œâ”€â”€ checkpoint-100/             # Checkpoints intermedi
â”‚   â”œâ”€â”€ checkpoint-200/
â”‚   â””â”€â”€ adapter_model.bin          # LoRA adapter finale
â”œâ”€â”€ final_model_gguf/              # Modello finale per LMStudio
â”‚   â”œâ”€â”€ medical_qwen3_q4km.gguf   # Modello fine-tunato
â”‚   â”œâ”€â”€ model_info.txt             # Info modello
â”‚   â””â”€â”€ README.md                  # Istruzioni LMStudio
â””â”€â”€ training_gguf.log              # Log completo
```

## ðŸŽ¯ Risultato Finale

**Modello**: `medical_qwen3_q4km.gguf`  
**Compatibile**: âœ… LMStudio  
**Dimensione**: ~4-6GB (simile a originale)  
**QualitÃ **: Mantiene intelligenza base + medicina  

## ðŸ’¡ Uso in LMStudio

### 1. **Importa il Modello**
```
LMStudio â†’ Models â†’ Import Model
Seleziona: final_model_gguf/medical_qwen3_q4km.gguf
```

### 2. **Configura Parametri**
```
Temperature: 0.7
Max Tokens: 2048
Top P: 0.9
System Prompt: "Sei un assistente medico esperto."
```

### 3. **Test il Modello**
```
Domanda: "Quali sono i sintomi del diabete?"
Risposta: [Risposta medica accurata in italiano]
```

## âš¡ Parametri Ottimizzati per 8GB VRAM

| Parametro | Valore | PerchÃ©? |
|-----------|---------|---------|
| **Batch Size** | 1 | Riduce uso memoria |
| **Gradient Accumulation** | 8 | Simula batch 8 |
| **LoRA Rank** | 4 | Basso per 8GB VRAM |
| **LoRA Alpha** | 8 | Rapporto ottimale |
| **Max Length** | 512 | Limitato per memoria |
| **Quantization** | Q4_K_M | GiÃ  ottimizzato |
| **Learning Rate** | 3e-5 | Standard fine-tuning |
| **Epochs** | 2 | Sufficiente per adattamento |

## ðŸ”§ Risoluzione Problemi

### **"CUDA out of memory"**
- Riduci `cutoff_length` a 256
- Diminuisci LoRA rank a 2
- Aumenta gradient accumulation a 16

### **"Modello troppo grande"**
- Il tuo Q4_K_M Ã¨ ~4-6GB, perfetto per 8GB VRAM
- Training temporaneo usa ~2-3GB aggiuntivi

### **Training lento**
- Normale: 4-8 ore per 2 epochs completi
- Dipende da complessitÃ  dataset medico

## ðŸ“ˆ Monitoraggio Progresso

Lo script mostra:
- **Progresso training** (step/epoch)
- **Uso memoria GPU** (GB liberi/usati)
- **Loss** (deve diminuire)
- **Tempo stimato** rimanente

## ðŸŽ¯ Risultati Attesi

Dopo il training, il tuo modello sarÃ  in grado di:

âœ… **Rispondere a domande mediche** in italiano e inglese  
âœ… **Spiegare sintomi e trattamenti** dettagliatamente  
âœ… **Mantenere coerenza medica** nelle risposte  
âœ… **Adattarsi al tuo dataset** tecnico specifico  
âœ… **Funzionare perfettamente** in LMStudio  

## ðŸ”’ Protezioni Termiche (Sicurezza Hardware)

Lo script include **sistemi avanzati di protezione** per il tuo hardware:

### ðŸŒ¡ï¸ **Monitoraggio Temperature**
- **CPU**: Monitoraggio continuo (max 85Â°C)
- **GPU**: Controllo temperatura AMD (max 83Â°C)
- **Alert automatici** se temperature troppo alte
- **Log dettagliato** temperature ogni 30 secondi

### âš¡ **Ottimizzazioni Automatiche**
- **Riduzione batch size** se CPU > 80Â°C
- **Aumento gradient accumulation** per raffreddamento
- **Limitazione thread CPU** (max 4 threads)
- **Gestione memoria** ottimizzata

### ðŸ›‘ **Sicurezza Critica**
- **Arresto automatico** se GPU > 87Â°C (temperatura critica)
- **Interruzione sicura** con Ctrl+C (salva progressi)
- **Recovery mode** per riprendere da checkpoint
- **No overclocking** - usa impostazioni sicure

### ðŸ“Š **Parametri Sicuri di Default**
```
CPU Max: 85Â°C     (soglia allerta: 80Â°C)
GPU Max: 83Â°C     (soglia allerta: 78Â°C)
Critical: 87Â°C    (arresto automatico)
CPU Usage: <90%   (monitoraggio continuo)
Memory: <95%      (gestione automatica)
```

## ðŸš€ Comando Finale

```bash
# Esegui e attendi 4-8 ore (con protezioni attive)
python setup_and_train_gguf.py

# Il tuo modello sarÃ  pronto per LMStudio!
# Monitoraggio temperature attivo durante tutto il training
```

**ðŸ”’ Il tuo hardware Ã¨ protetto!** Lo script monitora e ottimizza automaticamente per evitare surriscaldamento.

**ðŸ’¡ Suggerimenti per temperature ottimali:**
- Assicurati di avere **buona ventilazione**
- **Pulisci le ventole** se necessario
- Considera **undervolting** se hai esperienza
- Usa **HWiNFO64** per monitorare in Windows

**Buon training sicuro!** ðŸŽ¯ Il tuo assistente medico AI sta per nascere, senza stress per il tuo hardware!